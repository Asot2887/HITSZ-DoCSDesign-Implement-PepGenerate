{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense,Reshape,Activation,BatchNormalization,UpSampling2D,Conv2D,Flatten,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt  \n",
    "\n",
    "import argparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# # 创建解析\n",
    "# parser = argparse.ArgumentParser(description=\"train flower classify\",\n",
    "#                                  formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "# # 添加参数\n",
    "# parser.add_argument('--train_url', type=str,\n",
    "#                     help='the path model saved')\n",
    "# parser.add_argument('--data_url', type=str, help='the training data')\n",
    "# # 解析参数\n",
    "# args, unkown = parser.parse_known_args()\n",
    "\n",
    "# data_path = args.data_url\n",
    "# train_path = args.train_url\n",
    "data_path = './'\n",
    "train_path = './GAN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    #添加2维卷积层，卷积核大小为5×5，激活函数为tanh，输入shape在‘channels_first’模式下为（samples,channels，rows，cols）\n",
    "    #在‘channels_last’模式下为（samples,rows,cols,channels），输出为64维\n",
    "    model.add(\n",
    "            Conv2D(64, (5, 5),\n",
    "            padding='same',\n",
    "            input_shape=(28, 28, 1))\n",
    "            )\n",
    "    model.add(Activation('tanh'))\n",
    "    #为空域信号施加最大值池化，pool_size取（2，2）代表使图片在两个维度上均变为原长的一半\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (5, 5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #Flatten层把多维输入一维化，常用在从卷积层到全连接层的过渡\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    #一个结点进行二值分类，并采用sigmoid函数的输出作为概念\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generator_containing_discriminator(g, d):\n",
    "    #将前面定义的生成器架构和判别器架构组拼接成一个大的神经网络，用于判别生成的图片\n",
    "    model = Sequential()\n",
    "    #先添加生成器架构，再令d不可训练，即固定d\n",
    "    #因此在给定d的情况下训练生成器，即通过将生成的结果投入到判别器进行辨别而优化生成器\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    #生成图片拼接\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    \n",
    "    # 国内好像不能直接导入数据集，我们试了几次都不行，后来将数据集下载到本地'~/.keras/datasets/'，也就是当前目录（我的是用户文件夹下）下的.keras文件夹中。\n",
    "    #下载的地址为：https://s3.amazonaws.com/img-datasets/mnist.npz\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data(data_path+'mnist.npz')\n",
    "    #iamge_data_format选择\"channels_last\"或\"channels_first\"，该选项指定了Keras将要使用的维度顺序。\n",
    "    #\"channels_first\"假定2D数据的维度顺序为(channels, rows, cols)，3D数据的维度顺序为(channels, conv_dim1, conv_dim2, conv_dim3)\n",
    "    \n",
    "    #转换字段类型，并将数据导入变量中\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None]\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    # X_train = X_train.reshape((X_train.shape, 1) + X_train.shape[1:])\n",
    "    \n",
    "    #将定义好的模型架构赋值给特定的变量\n",
    "    d = discriminator_model()\n",
    "    g = generator_model()\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "    \n",
    "    #定义生成器模型判别器模型更新所使用的优化算法及超参数\n",
    "    d_optim = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    #编译三个神经网络并设置损失函数和优化算法，其中损失函数都是用的是二元分类交叉熵函数。编译是用来配置模型学习过程的\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    \n",
    "    #前一个架构在固定判别器的情况下训练了生成器，所以在训练判别器之前先要设定其为可训练。\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    epochs = 100\n",
    "    gloss = []\n",
    "    dloss = []\n",
    "    #下面在满足epoch条件下进行训练\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        \n",
    "        #计算一个epoch所需要的迭代数量，即训练样本数除批量大小数的值取整；其中shape[0]就是读取矩阵第一维度的长度\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        \n",
    "        #在一个epoch内进行迭代训练\n",
    "        newg = 0\n",
    "        newd = 0\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            \n",
    "            #随机生成的噪声服从均匀分布，且采样下界为-1、采样上界为1，输出BATCH_SIZE×100个样本；即抽取一个批量的随机样本\n",
    "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "            \n",
    "            #抽取一个批量的真实图片\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            #生成的图片使用生成器对随机噪声进行推断；verbose为日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录\n",
    "            generated_images = g.predict(noise, verbose=0)\n",
    "            \n",
    "            #每经过100次迭代输出一张生成的图片\n",
    "            if index % 100 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\n",
    "                    train_path+str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            \n",
    "            #将真实的图片和生成的图片以多维数组的形式拼接在一起，真实图片在上，生成图片在下\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            #生成图片真假标签，即一个包含两倍批量大小的列表；前一个批量大小都是1，代表真实图片，后一个批量大小都是0，代表伪造图片\n",
    "            y = np.asarray([1] * BATCH_SIZE + [0] * BATCH_SIZE)\n",
    "            \n",
    "            #判别器的损失；在一个batch的数据上进行一次参数更新\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            \n",
    "            #随机生成的噪声服从均匀分布\n",
    "            noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "            #固定判别器\n",
    "            d.trainable = False\n",
    "            \n",
    "            #计算生成器损失；在一个batch的数据上进行一次参数更新\n",
    "            LabelOfBatch = []\n",
    "            for i in range(BATCH_SIZE):\n",
    "                LabelOfBatch.append(1)\n",
    "            LabelOfBatch = np.asarray(LabelOfBatch)\n",
    "            g_loss = d_on_g.train_on_batch(noise, LabelOfBatch)\n",
    "            \n",
    "            #令判别器可训练\n",
    "            d.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            \n",
    "            #每100次迭代保存一次生成器和判别器的权重\n",
    "            newd = d_loss\n",
    "            newg = g_loss\n",
    "            if index % 100 == 9:\n",
    "                g.save_weights(train_path + 'generator', True)\n",
    "                d.save_weights(train_path + 'discriminator', True)\n",
    "        gloss.append(newg)\n",
    "        dloss.append(newd)\n",
    "    plt.plot(gloss, label='g_loss')\n",
    "    plt.plot(dloss, label = 'd_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(train_path + 'lossplt.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def generate(BATCH_SIZE, nice= False ):\n",
    "    #训练完模型后，可以运行该函数生成图片\n",
    "    g = generator_model()\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=0)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"./GAN/generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 1875\n",
      "batch 0 d_loss : 0.683669\n",
      "batch 0 g_loss : 0.654482\n",
      "batch 1 d_loss : 0.663553\n",
      "batch 1 g_loss : 0.646298\n",
      "batch 2 d_loss : 0.638896\n",
      "batch 2 g_loss : 0.617776\n",
      "batch 3 d_loss : 0.625448\n",
      "batch 3 g_loss : 0.609708\n",
      "batch 4 d_loss : 0.578926\n",
      "batch 4 g_loss : 0.596226\n",
      "batch 5 d_loss : 0.559564\n",
      "batch 5 g_loss : 0.584616\n",
      "batch 6 d_loss : 0.542539\n",
      "batch 6 g_loss : 0.574087\n",
      "batch 7 d_loss : 0.519312\n",
      "batch 7 g_loss : 0.559171\n",
      "batch 8 d_loss : 0.497305\n",
      "batch 8 g_loss : 0.535623\n",
      "batch 9 d_loss : 0.483976\n",
      "batch 9 g_loss : 0.523407\n",
      "batch 10 d_loss : 0.474439\n",
      "batch 10 g_loss : 0.524673\n",
      "batch 11 d_loss : 0.459333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\zhuomianmian\\Compulsory\\BSoftwareProgram\\period\\608\\demo_lyz.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/zhuomianmian/Compulsory/BSoftwareProgram/period/608/demo_lyz.ipynb#ch0000005?line=0'>1</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/zhuomianmian/Compulsory/BSoftwareProgram/period/608/demo_lyz.ipynb#ch0000005?line=1'>2</a>\u001b[0m train(batch_size)\n",
      "\u001b[1;32me:\\zhuomianmian\\Compulsory\\BSoftwareProgram\\period\\608\\demo_lyz.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(BATCH_SIZE)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/zhuomianmian/Compulsory/BSoftwareProgram/period/608/demo_lyz.ipynb#ch0000003?line=77'>78</a>\u001b[0m     LabelOfBatch\u001b[39m.\u001b[39mappend(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/zhuomianmian/Compulsory/BSoftwareProgram/period/608/demo_lyz.ipynb#ch0000003?line=78'>79</a>\u001b[0m LabelOfBatch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(LabelOfBatch)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/zhuomianmian/Compulsory/BSoftwareProgram/period/608/demo_lyz.ipynb#ch0000003?line=79'>80</a>\u001b[0m g_loss \u001b[39m=\u001b[39m d_on_g\u001b[39m.\u001b[39;49mtrain_on_batch(noise, LabelOfBatch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/zhuomianmian/Compulsory/BSoftwareProgram/period/608/demo_lyz.ipynb#ch0000003?line=81'>82</a>\u001b[0m \u001b[39m#令判别器可训练\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/zhuomianmian/Compulsory/BSoftwareProgram/period/608/demo_lyz.ipynb#ch0000003?line=82'>83</a>\u001b[0m d\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swb\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1695\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1690'>1691</a>\u001b[0m   iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x,\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1691'>1692</a>\u001b[0m                                                 y, sample_weight,\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1692'>1693</a>\u001b[0m                                                 class_weight)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1693'>1694</a>\u001b[0m   train_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1694'>1695</a>\u001b[0m   logs \u001b[39m=\u001b[39m train_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1696'>1697</a>\u001b[0m \u001b[39mif\u001b[39;00m reset_metrics:\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1697'>1698</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_metrics()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swb\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=777'>778</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=778'>779</a>\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=779'>780</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=781'>782</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=782'>783</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swb\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:807\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=803'>804</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=804'>805</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=805'>806</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=806'>807</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=807'>808</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=808'>809</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=809'>810</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/def_function.py?line=810'>811</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swb\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=2826'>2827</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=2827'>2828</a>\u001b[0m   graph_function, args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=2828'>2829</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_filtered_call(args, kwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swb\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1826'>1827</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_filtered_call\u001b[39m(\u001b[39mself\u001b[39m, args, kwargs, cancellation_manager\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1827'>1828</a>\u001b[0m   \u001b[39m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1828'>1829</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1829'>1830</a>\u001b[0m \u001b[39m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1840'>1841</a>\u001b[0m \u001b[39m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1841'>1842</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1842'>1843</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1843'>1844</a>\u001b[0m       [t \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m nest\u001b[39m.\u001b[39;49mflatten((args, kwargs), expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1844'>1845</a>\u001b[0m        \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(t, (ops\u001b[39m.\u001b[39;49mTensor,\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1845'>1846</a>\u001b[0m                          resource_variable_ops\u001b[39m.\u001b[39;49mBaseResourceVariable))],\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1846'>1847</a>\u001b[0m       captured_inputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcaptured_inputs,\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1847'>1848</a>\u001b[0m       cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swb\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1917'>1918</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m (\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1918'>1919</a>\u001b[0m     pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1919'>1920</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1920'>1921</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1921'>1922</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1922'>1923</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1923'>1924</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1924'>1925</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1925'>1926</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1926'>1927</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1927'>1928</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=1928'>1929</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swb\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=542'>543</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=543'>544</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=544'>545</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=545'>546</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=546'>547</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=547'>548</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=548'>549</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=549'>550</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=550'>551</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=551'>552</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=552'>553</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=553'>554</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=556'>557</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/function.py?line=557'>558</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swb\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda3/envs/swb/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train(batch_size)\n",
    "# generate(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60bff9b272fedff1fa90ce0dbeee5551a5297cee346565f639bed6524c8875b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('swb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
